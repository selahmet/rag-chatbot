{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0727afcb-c3bc-4af9-a3b1-05a5c29fbc9b",
   "metadata": {},
   "source": [
    "# Generative AI Temelleri \n",
    "\n",
    "## 1. GenAI Temelleri ve Kavramlar\n",
    "\n",
    "* **LLM:** İstemleri olasılıksal olarak sürdüren, milyarlarca parametreli ve geniş metinlerle eğitilmiş genel amaçlı dil modelidir.\n",
    "* **Transformer Mimarisi:** Girdideki öğeler arası bağıntıları self-attention ile modelleyen, paralel hesaplamaya elverişli derin sinir ağı mimarisidir.\n",
    "* **Token:** Modelin işlediği en küçük birimdir; kelime, alt kelime veya karakter olabilir ve uzunluk/maliyet bu birimlerle ölçülür.\n",
    "* **Context Window:** Modelin tek seferde işleyip “hatırlayabildiği” azami token bütçesidir (girdi+çıktı) ve aşıldığında önceki bağlam dışarıda kalır.\n",
    "* **System Instructions:** Modelin rolünü, sınırlarını ve üslubunu belirleyen; diğer iletilere göre önceliği yüksek üst seviye talimatlardır.\n",
    "* **Hallucination:** Modelin gerçek veriye dayanmayan fakat tutarlı görünen bilgi uydurmasıdır ve RAG/ek doğrulama ile azaltılabilir.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2. LLM-Based Uygulama Geliştirme: Temel Enstrümanlar\n",
    "\n",
    "### 2.1. Model Seçimi \n",
    "\n",
    "- **Api based modeller:** Claude, OpenAI, Google (Gemini) vb.\n",
    "- **Local Modeller:** Deepseek, Google (Gemma), Kumru vb.\n",
    "- **Model Büyüklüğü:** 2B, 7B, 40B \n",
    "- **Multimodel:** Text, image, audio vb.\n",
    " \n",
    "### 2.2. Prompt (İstek/Talimat)\n",
    "\n",
    "Prompt, modele ne yapmasını istediğinizi söyleyen metindir.\n",
    "\n",
    "- **Prompt Anatomisi**:\n",
    "```\n",
    "[System Instruction] + [Context] + [Task] + [Format] + [Examples]\n",
    "```\n",
    "\n",
    "- **Prompt Kalitesi = Output Kalitesi**\n",
    "\n",
    "### 2.3. Model Parametreleri\n",
    "\n",
    "- **temperature:** Örnekleme rastgeleliğini belirler; yüksek değer daha yaratıcı/dağınık, düşük değer daha tutarlı/tekrarlanabilir çıktılar verir.\n",
    "- **max_output_tokens** Modelin tek yanıtta üreteceği azami token sayısını sınırlar ve hem kesilme riskini hem de maliyet/gecikmeyi etkiler.\n",
    "- **top_p:** Olasılık kütlesinden p eşiğine kadar bir “çekirdek” oluşturup seçimleri bu alt kümeden yapar.\n",
    "- **top_k:** En olası k aday token arasından seçim yaparak çeşitlilik ile tutarlılık arasında denge kurar.\n",
    "\n",
    "### 2.4. Ek Enstrümanlar\n",
    "\n",
    "- **Safety Settings**: Zararlı içerik filtreleme\n",
    "- **Function Calling**: External tool'lara erişim\n",
    "- **Response Schema**: Structured output (JSON)\n",
    "- **vb.**\n",
    "\n",
    "## 3. Gemini Modelleri - [Gemini Docs](https://ai.google.dev/gemini-api/docs?hl=tr)\n",
    "\n",
    "* Gemini 2.0 Flash\n",
    "* Ücretsiz API Key\n",
    "* Large Context Window\n",
    "* Multimodel\n",
    "* Hızlı\n",
    "\n",
    "\n",
    "## 4. Gemini API Key Alma ve Kurulum\n",
    "\n",
    "### 4.1. API Key Alma\n",
    "\n",
    "1. **Google AI Studio'ya gidin**: [https://aistudio.google.com/](https://aistudio.google.com/)\n",
    "2. Google hesabınızla giriş yapın\n",
    "3. Sol menüden **\"Get API Key\"** seçeneğine tıklayın\n",
    "4. **\"Create API Key\"** butonuna basın\n",
    "5. Yeni bir API key oluşturun veya mevcut bir projeye ekleyin\n",
    "6. API key'inizi kopyalayın ve güvenli bir yerde saklayın\n",
    "\n",
    "**Güvenlik Uyarısı**: API key'inizi asla public repository'lere commit etmeyin! [(.gitignore)](https://github.com/github/gitignore/blob/main/Python.gitignore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d4004a-0f6e-4bdf-b22c-0ed08bd2f0b1",
   "metadata": {},
   "source": [
    "### 4.2. Python SDK Kurulumu\n",
    "\n",
    "```bash\n",
    "# Google Generative AI SDK'sını yükleyin\n",
    "pip install -q -U google-generativeai\n",
    "\n",
    "# Alternatif: requirements.txt dosyasına ekleyin\n",
    "\"google-generativeai>=0.8.3\" \n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54bf338-46a4-44b3-91f2-e3ac63c63b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kurulum\n",
    "#pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899c839-4059-4119-9e93-27ffe5f09c55",
   "metadata": {},
   "source": [
    "### 4.3. İlk Yapılandırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cdf0ef-0f76-4551-9977-2c835bb6527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b62692-c0cd-4ec2-9f2b-44ec9987fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the model\n",
    "version = 'models/gemini-2.0-flash'\n",
    "model = genai.GenerativeModel(version)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a74dad-3fce-40d3-9f40-6c5a4b2ee62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content('Selamlar nasılsın, şuan bir eğitimdeyiz herkese selam söyle.')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec331a-db03-4b6b-bc6a-a6ab32fc84b6",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a4a36-2597-4abb-845c-d853cbd53613",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "prompt = \"Global AI Hub hakkında sadece 1 cümlelik bilgi ver.\"\n",
    "for i in range(5):\n",
    "  response = model.generate_content(prompt)\n",
    "  outputs.append(response.text)\n",
    "for index, sentence in enumerate(outputs, start=1):\n",
    "    print(f\"{index}. {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9da7a3-ed50-481c-b1f6-758e02aa8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in genai.list_models():\n",
    "    if m.name == 'models/gemini-2.0-flash':\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55044134-365c-4607-96bd-cfa85566872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gemini-2.0-flash'\n",
    "new_outputs = []\n",
    "low_temp_model = genai.GenerativeModel(model_name, generation_config={\"temperature\": 0})\n",
    "for i in range(5):\n",
    "  response = low_temp_model.generate_content(prompt)\n",
    "  new_outputs.append(response.text)\n",
    "for index, sentence in enumerate(new_outputs, start=1):\n",
    "    print(f\"{index}. {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734178a9-de2d-44c5-9656-a972310785d7",
   "metadata": {},
   "source": [
    "## Max Output Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ac4e7-81b5-4348-80fc-4e968747a13d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'gemini-2.0-flash'\n",
    "model = genai.GenerativeModel(model_name)\n",
    "\n",
    "prompt = \"Global AI Hub hakkında bilgi verir misiniz?\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85750e51-df5a-43b9-8ebb-92d6d253b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gemini-2.0-flash'\n",
    "short_response_model = genai.GenerativeModel(model_name, generation_config={\"max_output_tokens\": 200})\n",
    "prompt = \"Global AI Hub hakkında bilgi verir misiniz?\"\n",
    "response = short_response_model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a7753b-d759-4424-8f05-99d344a29420",
   "metadata": {},
   "source": [
    "## Token Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68c3dd-f854-475c-b9e3-381de31d7aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gemini-2.0-flash'\n",
    "token_n_model = genai.GenerativeModel(model_name, generation_config={\"temperature\": 0.5})\n",
    "poem_prompt = \"Bilgisayarlar hakkında az bilinen 5 bilgi ver.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89bbabd-7dcb-4c58-94ba-72d499b4385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = token_n_model.generate_content(poem_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd867277-684f-4f21-9134-a19794822bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_token_count = token_n_model.count_tokens(poem_prompt)\n",
    "output_token_count = token_n_model.count_tokens(response.text)\n",
    "print(f'Tokens in prompt: {prompt_token_count} \\n Estimated tokens in output {output_token_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0330f8-1452-45c0-a1bc-2ff2094ca990",
   "metadata": {},
   "source": [
    "### Promt teknikleri\n",
    "\n",
    "### 5.1. Açık ve Net Talimatlar\n",
    "\n",
    "❌ **Kötü Prompt:**\n",
    "```python\n",
    "prompt = \"Python hakkında bir şeyler söyle.\"\n",
    "```\n",
    "\n",
    "✅ **İyi Prompt:**\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Python programlama dilinin aşağıdaki özelliklerini açıkla:\n",
    "1. Liste comprehension nedir ve nasıl kullanılır?\n",
    "2. Decorator'lar ne işe yarar?\n",
    "3. Generator fonksiyonları neden kullanılır?\n",
    "\n",
    "Her madde için bir kod örneği ver.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ae4d5-c594-426b-89a8-7cad0945fbaa",
   "metadata": {},
   "source": [
    "## System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ed016-b1c7-4c88-8e29-a473601b8695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name='gemini-2.0-flash',\n",
    "    system_instruction=\"\"\"\n",
    "    Sen bir Python programlama öğretmenisin.\n",
    "    Yanıtlarında:\n",
    "    - Her zaman kod örnekleri ver\n",
    "    - Basit ve anlaşılır dil kullan\n",
    "    - Örnekleri adım adım açıkla\n",
    "    - Best practices'e uygun kod yaz\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "response = model.generate_content(\"Fonksiyon nasıl yazılır?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86481a15-50a3-44ba-8b86-05e982a793bd",
   "metadata": {},
   "source": [
    "### 5.3. Role-Based Prompting (Rol Tanımlama)\n",
    "\n",
    "Modele bir rol vererek yanıt kalitesini artırabilirsiniz.\n",
    "\n",
    "**Örnek Roller:**\n",
    "- Uzman: \"Sen bir cybersecurity uzmanısın...\"\n",
    "- Öğretmen: \"Sen bir matematik öğretmenisin...\"\n",
    "- Analist: \"Sen bir finansal analistsin...\"\n",
    "- Asistan: \"Sen yardımcı bir kodlama asistanısın...\"\n",
    "\n",
    "### 5.4. Context Sağlama (Bağlam)\n",
    "\n",
    "Yeterli bağlam vermek, daha iyi sonuçlar üretir.\n",
    "\n",
    "```python\n",
    "\n",
    "prompt = \"\"\"\n",
    "BAĞLAM:\n",
    "Bir e-ticaret şirketi için çalışıyorum. Müşteri memnuniyetini artırmak istiyoruz.\n",
    "Şu anda müşteriler sipariş takibinde zorluk yaşıyor.\n",
    "\n",
    "GÖREV:\n",
    "Sipariş takip sistemini iyileştirmek için 5 pratik öneri sun.\n",
    "\n",
    "KISITILAR:\n",
    "- Bütçe: 50.000 TL\n",
    "- Süre: 3 ay\n",
    "- Ekip: 3 yazılımcı\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### 5.5. Format Belirleme\n",
    "\n",
    "#### 5.5.1. Markdown Formatı\n",
    "\n",
    "```python\n",
    "\n",
    "prompt = \"\"\"\n",
    "Python'da hata yakalama (exception handling) konusunu açıkla.\n",
    "\n",
    "FORMAT:\n",
    "- Markdown kullan\n",
    "- Başlıkları ### ile belirt\n",
    "- Kod bloklarını ``` ile çevrele\n",
    "- Önemli noktaları **bold** yap\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### 5.5.2. JSON Formatı (Structured Output)\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Aşağıdaki bilgileri JSON formatında döndür:\n",
    "\n",
    "Kişi bilgileri:\n",
    "- Ad: Ahmet Yılmaz\n",
    "- Yaş: 30\n",
    "- Meslek: Yazılım Geliştirici\n",
    "- Şehir: İstanbul\n",
    "- Diller: Python, JavaScript, Java\n",
    "\n",
    "JSON şeması:\n",
    "{\n",
    "  \"name\": \"string\",\n",
    "  \"age\": number,\n",
    "  \"profession\": \"string\",\n",
    "  \"city\": \"string\",\n",
    "  \"languages\": [\"string\"]\n",
    "}\n",
    "\n",
    "Sadece JSON çıktısı ver, başka açıklama ekleme.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b1696-be58-46dd-8bdc-e44a7b7aa740",
   "metadata": {},
   "source": [
    "## Zero-Shot Prompting\n",
    "- Hiç örnek vermeden direkt görev tanımlama.\n",
    "  \n",
    "**Ne zaman kullanılır:**\n",
    "- Model zaten görevi iyi biliyorsa\n",
    "- Hızlı test ve prototipleme için\n",
    "- Basit görevler için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ebf46f-56f4-4c15-b2e0-0efee62438fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "# Zero-shot: Örnek yok\n",
    "prompt = \"\"\"\n",
    "Aşağıdaki cümlenin sentiment'ini (duygu durumunu) belirle:\n",
    "\"Bu ürün gerçekten harika, çok memnun kaldım!\"\n",
    "\n",
    "Sentiment: ?\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05adf86-77de-4d06-bc80-709a0c3a186f",
   "metadata": {},
   "source": [
    "## Few-Shot Learning (Örneklerle Öğretme)\n",
    "- Birkaç örnek vererek modeli yönlendirme.\n",
    "\n",
    "**Optimal Örnek Sayısı:**\n",
    "- 1-5 örnek genellikle yeterli\n",
    "- Çok fazla örnek token limitini şişirir\n",
    "- Çeşitli örnekler (edge cases) dahil edin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf30803-ef1c-4e93-b399-d325e8f399bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "# Few-shot: Örnekler var\n",
    "prompt = \"\"\"\n",
    "Sentiment analizi yap (Pozitif/Negatif/Nötr):\n",
    "\n",
    "Örnek 1:\n",
    "Cümle: \"Bu restoran muhteşemdi, kesinlikle tekrar geleceğim!\"\n",
    "Sentiment: Pozitif\n",
    "\n",
    "Örnek 2:\n",
    "Cümle: \"Servis çok yavaştı ve yemekler soğuktu.\"\n",
    "Sentiment: Negatif\n",
    "\n",
    "Örnek 3:\n",
    "Cümle: \"Fiyatlar normal seviyede.\"\n",
    "Sentiment: Nötr\n",
    "\n",
    "Şimdi sen analiz et:\n",
    "Cümle: \"Ürün beklediğimden iyi çıktı ama kargo çok geç geldi.\"\n",
    "Sentiment: ?\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac09388-1d50-431e-8ce3-8094d06379db",
   "metadata": {},
   "source": [
    "## Chain-of-Thought (Düşünce Zinciri)\n",
    "- Modelden adım adım düşünmesini isteme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9823515-2570-4abb-afb1-3d58e3238853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "prompt = \"\"\"\n",
    "Aşağıdaki problemi çöz ve düşünce sürecini açıkla:\n",
    "\n",
    "PROBLEM:\n",
    "Bir şirketin 3 aylık satış verileri:\n",
    "- Ocak: 120.000 TL\n",
    "- Şubat: 150.000 TL  \n",
    "- Mart: 135.000 TL\n",
    "\n",
    "Sorular:\n",
    "1. Ortalama aylık satış nedir?\n",
    "2. En yüksek artış hangi ayda oldu?\n",
    "3. Toplam satış nedir?\n",
    "\n",
    "ÇÖZÜM:\n",
    "Her soruyu ayrı ayrı ve adım adım çöz.\n",
    "Her adımda yaptığın hesaplamayı açıkla.\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ddf0a-f9bf-4252-85e8-6bcf8b6efecb",
   "metadata": {},
   "source": [
    "## Bağlamı koruyarak chat in devam etmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1c736c-a8b5-4a45-be8b-2e83c892963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "# Chat oturumu başlat\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "# İlk mesaj\n",
    "response1 = chat.send_message(\"Python öğrenmek istiyorum. Nereden başlamalıyım?\")\n",
    "print(\"Bot:\", response1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702b095-c117-43d3-b2ac-da23a0822ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# İkinci mesaj (bağlam korunur)\n",
    "response2 = chat.send_message(\"Peki, hangi IDE'yi önerirsin?\")\n",
    "print(\"Bot:\", response2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1309257-364a-4df8-b7bd-a0d76dd53408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Üçüncü mesaj\n",
    "response3 = chat.send_message(\"VS Code nasıl kurarım?\")\n",
    "print(\"Bot:\", response3.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527b537-727c-47d9-8b2d-de086dbb52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sohbet geçmişini görüntüle\n",
    "print(\"\\n--- Sohbet Geçmişi ---\")\n",
    "for message in chat.history:\n",
    "    print(f\"{message.role}: {message.parts[0].text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b3811-c7cc-40ed-aa2e-4d869e5d401d",
   "metadata": {},
   "source": [
    "## Hepsini bir araya getirelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590bc7d-9d68-44b7-9b79-86ba04f88be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    'temperature': 0.7,\n",
    "    'top_p': 0.95,\n",
    "    'top_k': 40,\n",
    "    'max_output_tokens': 2048,\n",
    "}\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"Sen bir öğrenme yol haritası danışmanısın. Kullanıcıların herhangi bir konuda (teknik veya teknik olmayan) adım adım öğrenme planları oluşturmasına yardım ediyorsun.\n",
    "\n",
    "Her roadmap için şunları sun:\n",
    "1. Genel Bakış: Konu neden önemli\n",
    "2. Ön Koşullar: Ne bilmesi gerekiyor\n",
    "3. Öğrenme Yolu: Fazlar halinde (her faz için süre, konular, kaynaklar, projeler)\n",
    "4. Kilometre Taşları: İlerleme ölçüm noktaları\n",
    "5. İpuçları: Dikkat edilmesi gerekenler\n",
    "\n",
    "Destekleyici, gerçekçi, Türkçe/İngilizce kaynaklar öner. Gerekirse detay sor.\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name='gemini-2.0-flash',\n",
    "    generation_config=MODEL_CONFIG,\n",
    "    system_instruction=SYSTEM_PROMPT\n",
    ")\n",
    "\n",
    "\n",
    "def chat_function(message, history):\n",
    "    if not message or message.strip() == \"\":\n",
    "        return \"Lütfen bir mesaj yazın.\"\n",
    "    \n",
    "    chat_history = []\n",
    "    for human, assistant in history:\n",
    "        if human and assistant:\n",
    "            chat_history.append({\"role\": \"user\", \"parts\": [human]})\n",
    "            chat_history.append({\"role\": \"model\", \"parts\": [assistant]})\n",
    "    \n",
    "    chat = model.start_chat(history=chat_history)\n",
    "    response = chat.send_message(message.strip())\n",
    "    return response.text\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_function,\n",
    "    title=\"Roadmap AI\",\n",
    "    description=\"Herhangi bir konuda öğrenme yol haritası oluşturun\",\n",
    "    examples=[\n",
    "        \"Python öğrenmek istiyorum\",\n",
    "        \"Machine learning için roadmap\",\n",
    "        \"Fitness ve sağlıklı yaşam planı\",\n",
    "        \"İngilizce nasıl geliştiririm?\"\n",
    "    ],\n",
    "    theme=\"soft\"\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6c196-5a87-497d-a6a8-4c0514c29d63",
   "metadata": {},
   "source": [
    "## Sorular\n",
    "\n",
    "- Proje isteri neler, bizim burada yaptığımız neydi, bizden beklenen nedir? [Proje Dosyası](https://akbankgenerativeaigirisbootcamp.zulipchat.com/user_uploads/70582/RrDnc3ZCm0liXYu-pyn_xbGG/GAIH-GenAI-Bootcamp-Proje-Dosyas.pdf)\n",
    "- \n",
    "- Datayı nasıl bulacağım, kaggle dan data bulabilir miyim?\n",
    "- RAG yaptım ama chatbotum pek ahım şahım cevap vermiyor\n",
    "- AI destekli araçlar ile kod yazıyorum, öğrenmiyor gibi hissediyorum içim rahat değil\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
